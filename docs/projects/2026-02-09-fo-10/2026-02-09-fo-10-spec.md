# FO-10 Specification

**Created:** 2026-02-09
**Status:** Draft

## Braindump / introductory thoughts

FO-09 experience showed that AI-generated questions tend to "flounder" regardless of prompt engineering. The questions often lack direction or feel generic. The solution: take full control of the question sequence (hardcoded) while letting the LLM generate contextual chips/fragments that adapt to what the user has shared.

This is a "fixed rails, dynamic options" approach — the journey structure is predictable and well-crafted, while the personalization happens in the response options.

## Overview

FO-10 is an evolution of FO-09 that **replaces the dynamic discovery phase** with a **fixed 4-question sequence** (steps 4-7). The questions are hardcoded in the codebase. The chips and sentence options presented alongside each question are AI-generated based on accumulated user context.

Everything outside the discovery phase (welcome screens, familiarity, affirmation generation, card review, summary, post-review onboarding) remains identical to FO-09.

## Flow

### Complete Step Sequence

| Step | Screen | Type | Content |
|------|--------|------|---------|
| 0-2 | Welcome | Static | Welcome message + name input (identical to FO-09) |
| 3 | Familiarity | Static | "How familiar are you with affirmations?" — 3 selection buttons (identical to FO-09) |
| 4 | Goal | Fixed Q + predefined chips | "What is your primary goal with affirmations today, [name]?" |
| 5 | Why | Fixed Q + LLM fragments | "Why does this goal feel important to you?" |
| 6 | Situation | Fixed Q + LLM sentences | "In which situation is your goal especially important?" |
| 7 | Support tone | Fixed Q + LLM sentences | "What kind of support would be most helpful for you right now?" |
| 8 | Generation | Loading | Affirmation generation (5 per batch, identical to FO-09) |
| 9 | Card review | Interactive | Card-by-card "Love it" / "Discard" (identical to FO-09) |
| 10 | Summary | Interactive | "I'm good with these" / "I want to create more" (identical to FO-09) |
| 11-13 | Post-review | Static | Background, notifications, paywall mockups (identical to FO-09) |
| 14 | Completion | Static | All loved affirmations (identical to FO-09) |

### Discovery Phase Detail (Steps 4-7)

All discovery steps include a **text input field** where the user can type freely, plus chips for quick selection. This matches FO-09's interaction pattern.

#### Step 4: Goal — Predefined Flat Chips

**Question:** "What is your primary goal with affirmations today, [name]? Write as much as you like."

**Input:** Text field + predefined flat topic chips (same list as FO-09's `StepTopics`).

**Chip interaction:** Clicking a chip appends the topic text to the input field. User can also type freely. Same pattern as FO-09's `StepTopics` component.

**Chips are predefined (not AI-generated)** because there is no user context to personalize against yet. Uses the same 36 flat topic chips from FO-09:

Motivation, Focus, Inner peace, Energy boost, Better sleep, Body peace, Self-worth, Boundaries, Letting go, Healing, Gratitude, Positivity, Resilience, Anxiety relief, Stress relief, Courage, Hope, Joy, Patience, Mindfulness, Self-care, Forgiveness, Connection, Self-love, Breakup healing, Impulse control, Digital detox, Productivity, Morning boost, Night calm, Confidence, Calm, Self-discipline, Overthinking, Grief, Loneliness

**Note:** The `StepTopics` component pattern from FO-09 can be reused/adapted for this step.

#### Step 5: Why — LLM Fragments

**Question:** "Why does this goal feel important to you? Write as much or as little as you like."

**Input:** Text field + LLM-generated **hybrid fragments** (ending with "...").

**LLM context:** User's name, selected topics/goal from step 4, familiarity level.

**Chip interaction:** Clicking a fragment appends it to the text field for the user to complete (fragment mode, same as FO-09 screens 2+).

**Chip count:** 8 initial + 15 expanded (via "show more" button).

**Example fragments** (for a user who selected "Confidence" / "Speaking up at work"):
- "I've been holding back because..."
- "It matters to me because I..."
- "I'm tired of feeling like I..."
- "I want to finally be able to..."

#### Step 6: Situation — LLM Sentences

**Question:** "In which situation is your goal especially important? Write as much or as little as you like."

**Input:** Text field + LLM-generated **complete sentences**.

**LLM context:** User's name, goal (step 4), why it matters (step 5), familiarity level.

**Chip interaction:** Clicking a sentence replaces/sets the text field content (sentence mode, same as FO-09 screen 1).

**Chip count:** 8 initial + 15 expanded.

**Example sentences** (for a user focused on confidence at work):
- "When I need to present ideas in meetings"
- "When I'm asked for my opinion and freeze up"
- "When I compare myself to more experienced colleagues"

#### Step 7: Support Tone — LLM Sentences

**Question:** "What kind of support would be most helpful for you right now? Write as much or as little as you like."

**Input:** Text field + LLM-generated **complete sentences** about tone/style of support.

**LLM context:** Full conversation context from steps 4-6.

**Chip interaction:** Sentence mode (click to set).

**Chip count:** 8 initial + 15 expanded.

**Example sentences** (tone-based, adapted to conversation):
- "Gentle reminders that I'm doing okay"
- "Bold, empowering statements that push me forward"
- "Calm, grounding words for when I feel overwhelmed"
- "Warm encouragement, like a friend who believes in me"

### Heart Animation Transitions

Heart animation appears **between every discovery step transition** (4 animations total):
- Step 4 → Step 5: after goal submission
- Step 5 → Step 6: after "why" submission
- Step 6 → Step 7: after situation submission
- Step 7 → Generation: "Creating your personalized affirmations" message

Same component and pattern as FO-09. Messages follow FO-09's pattern ("Thank you for sharing, [name]...") with the final transition using the affirmation-creation message.

### Affirmation Engine (Steps 8-10)

**Identical to FO-09:**
- 5 affirmations per batch
- Card-by-card review: "Love it" / "Discard"
- Summary screen with "I'm good with these" / "I want to create more"
- Unlimited generation cycles with feedback loop (loved/discarded context)
- The affirmation agent receives the full conversation context from steps 4-7 via the exchanges array — the user's tone preference from step 7 is part of this context naturally

### Post-Review (Steps 11-14)

**Identical to FO-09:** Background selection, notifications, paywall mockups, completion screen.

## Technical Architecture

### What Changes from FO-09

| Component | FO-09 | FO-10 |
|-----------|-------|-------|
| Questions | AI-generated (dynamic) | Hardcoded in code |
| Discovery flow | 2-5 dynamic screens | Fixed 4 screens (steps 4-7) |
| Discovery agent | Generates questions + fragments | Single chip generation agent (chips only) |
| Step 4 chips | AI-generated sentences | Predefined flat topic chips (reuse FO-09 StepTopics list) |
| Steps 5-7 chips | AI-generated (mixed modes) | AI-generated: fragments (step 5), sentences (steps 6-7) |
| `readyForAffirmations` | AI decides | Not needed — fixed sequence, always proceeds after step 7 |
| Model | gpt-4o-mini (default) | gpt-4o |
| Implementations | 3 (default, two-lanes, bare-bones) | 1 (default only) |
| Affirmation generation | Identical | Identical |
| Card review / summary | Identical | Identical |
| Post-review screens | Identical | Identical |

### Chip Generation Agent

A single agent that generates only chips — no questions, no `readyForAffirmations` logic. Step-specific behavior is controlled via different **user prompt templates** (one per step).

**Model:** gpt-4o

**Input:** Step number, user context accumulated so far.
**Output:** `{ initialChips: string[], expandedChips: string[] }`

**Step-specific user prompt templates:**
- **Step 5 template:** Generate 8 + 15 hybrid fragments (end with "...") about why the user's goal matters
- **Step 6 template:** Generate 8 + 15 complete sentences about situations where the goal is important
- **Step 7 template:** Generate 8 + 15 complete sentences about tone/style of support

**System prompt:** Focused guidance on generating contextual chips. Much simpler than FO-09's discovery agent — no 5 Dimensions framework, no question generation, no readyForAffirmations logic. Just: "Given this user context, generate relevant response options."

### Reuse from FO-09

Components reused directly (imported from `app/fo-09/components/` or copied to `app/fo-10/components/`):
- `FragmentInput` — supports both `mode="sentences"` and `mode="fragments"`
- `HeartAnimation` — identical transition pattern
- `AffirmationCardFlow` — identical card review
- `AffirmationSummary` — identical summary with generate-more loop
- `StepWelcome` — steps 0-2 identical
- `StepFamiliarity` — step 3 identical
- `StepBackground`, `StepNotifications`, `StepPaywall` — post-review mockups
- `StepCompletion` — final screen
- `StepTopics` — reuse chip list pattern for step 4 (adapted for goal context)

Infrastructure reused:
- Affirmation agent (`fo-09-affirmation` or create `fo-10-affirmation`)
- `GatheringContext` type and exchange pattern
- KV store / template engine for prompt management
- Implementation context provider
- Server action patterns

### GatheringContext Adaptation

FO-09's `GatheringContext` stores exchanges as `{ question, answer }` pairs. FO-10 reuses this same structure — the questions are just hardcoded instead of AI-generated:

```typescript
// FO-10 hardcoded questions
export const FO10_QUESTIONS = [
  "What is your primary goal with affirmations today?",
  "Why does this goal feel important to you?",
  "In which situation is your goal especially important?",
  "What kind of support would be most helpful for you right now?",
] as const;

// The exchanges will look like:
exchanges: [
  { question: FO10_QUESTIONS[0], answer: { text: "..." } },
  { question: FO10_QUESTIONS[1], answer: { text: "..." } },
  { question: FO10_QUESTIONS[2], answer: { text: "..." } },
  { question: FO10_QUESTIONS[3], answer: { text: "..." } },
]
```

This means the affirmation agent receives the same data shape and can work without changes.

## Testing Strategy

### E2E Testing

Follow FO-09's E2E test structure (`e2e/fo-09.test.ts`) and create `e2e/fo-10.test.ts`.

**Run command:** `node --import tsx e2e/fo-10.test.ts`

**Test coverage areas:**

| Area | What to Test |
|------|-------------|
| Welcome (steps 0-2) | Same as FO-09 — name input, navigation |
| Familiarity (step 3) | Same as FO-09 — button selection |
| Goal chips (step 4) | Predefined chips render, chip click populates text field, free-text input works, continue button |
| Why fragments (step 5) | LLM chips load (wait for loading), fragment mode (append + "..." removal), 8 initial + "show more" for 15 expanded |
| Situation sentences (step 6) | LLM chips load, sentence mode (click to set), chip counts |
| Support tone (step 7) | LLM chips load, sentence mode, chip counts |
| Heart animations | Animation appears between each step transition (4 total) |
| Affirmation generation (step 8) | Loading state, 5 affirmations generated |
| Card review (step 9) | "Love it" / "Discard" per card, progress counter |
| Summary (step 10) | Loved affirmations displayed, "I'm good" and "create more" buttons |
| Generate more loop | "Create more" triggers new batch, feedback context passed |
| Post-review (steps 11-14) | Same as FO-09 — mockup screens, completion |

**Reusable helpers from FO-09 E2E:**
- `waitForText()`, `waitForTextContaining()`
- `waitForThinkingToFinish()`, `waitForHeartAnimation()`
- `clickButton()`, `clickSentence()`, `clickFragment()`
- `countChips()`, `countSentences()`, `countFragments()`
- `getTextareaValue()`

### Manual Verification

- **Chip quality:** Are LLM-generated fragments/sentences contextually relevant to what the user shared?
- **Mode correctness:** Do step 5 chips end with "..."? Do step 6-7 chips NOT end with "..."?
- **Tone variety:** Does step 7 produce meaningfully different tone options based on different user journeys?
- **Affirmation relevance:** Do generated affirmations reflect all 4 discovery answers, including tone preference?

### Edge Cases

- User types only (ignores all chips) — flow should still work
- User clicks chips without typing anything additional — flow should still work
- LLM returns fewer than 8 initial chips — UI should handle gracefully
- LLM returns fragments when sentences expected (or vice versa) — log warning, display as-is
- Empty text submission — should be blocked (require at least chip selection or typed text)

## Open Questions

All previously open questions have been resolved:
- ~~Exact predefined topics~~ → Use FO-09's flat 36-chip list
- ~~Heart animation messages~~ → Same pattern as FO-09, between every discovery step
- ~~Step 4 text input~~ → Yes, text input on all discovery steps (same as FO-09)
- ~~Implementations~~ → Single implementation, gpt-4o
- ~~Tone preference handling~~ → Part of conversation history, no special parameter
- ~~Agent architecture~~ → One chip agent with step-specific user prompt templates

## References

- FO-09 spec: `docs/projects/2026-01-30-fo-09/2026-01-30-fo-09-spec.md`
- FO-09 agent (discovery): `src/mastra/agents/fo-09/agent.ts`
- FO-09 agent (affirmation): `src/mastra/agents/fo-09/affirmation-agent.ts`
- FO-09 UI: `app/fo-09/components/fo-experience.tsx`
- FO-09 seed data (3 implementations): `src/db/seeds/fo-09.ts`
- FO-09 E2E test: `e2e/fo-09.test.ts`
- E2E testing setup: `docs/current/e2e-testing.md`
