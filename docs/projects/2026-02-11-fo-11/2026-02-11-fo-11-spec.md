# FO-11 Specification

**Created:** 2026-02-11
**Status:** Ready for Implementation

## Braindump / Introductory Thoughts

FO-10 proved that good affirmations come from well-structured discovery, but the hardcoded question sequence created two problems identified by the product manager:

1. **Redundancy:** Questions feel repetitive because the user often already answered the next question in their previous response. Example: user writes a rich goal answer that already explains the life context, then gets asked about life context anyway.
2. **Tone chips too specific:** Step 7's tone suggestions were full sentences like "Gentle reminders that I am capable of this interview" — too many things to agree or disagree with in a single chip. Single words like "Gentle", "Empowering", "Caring" work better.

FO-09 showed that fully dynamic LLM-generated questions drift and lose direction.

**FO-11 is the hybrid:** We tell the LLM *what each question should discover* (the intent), but let it formulate the actual question wording — and critically, let it **skip a question entirely** if the user already answered it. This preserves the structured discovery rails of FO-10 while adding the conversational adaptability of FO-09.

## Overview

FO-11 replaces FO-10's hardcoded question sequence with a **guided discovery agent** that receives structured intents for each step and returns adapted questions (or skip signals). The number of discovery steps is reduced from 4 to 3 (Goal, Context, Tone), and the previously open-ended "anything else" step is removed.

Everything outside the discovery phase (welcome screens, affirmation generation, card review, summary, post-review onboarding) remains identical to FO-10.

## Flow

### Complete Step Sequence

| Step | Screen | Type | Content |
|------|--------|------|---------|
| 0 | Welcome | Static | Welcome message |
| 1 | Name | Static | Name input |
| 2 | Personalized welcome | Static | "Welcome, [name]! Let us get to know you..." |
| 3 | Familiarity | Static | "How familiar are you with affirmations?" — 3 buttons (cosmetic only, not passed to discovery agent) |
| 4 | Goal | Static Q + static chips | "What's your main goal with affirmations today, [name]?" — static single-word chips |
| 5 | Context | LLM Q + LLM fragments | LLM-adapted question about life context — OR silently skipped |
| 6 | Tone | LLM Q + LLM single-word chips | LLM-adapted question about support tone — LLM-generated single-word chips |
| 7 | Generation | Loading | Affirmation generation (5 per batch) |
| 8 | Card review | Interactive | Card-by-card "Love it" / "Discard" (identical to FO-10) |
| 9 | Summary | Interactive | "I'm good with these" / "I want to create more" (identical to FO-10) |
| 10-12 | Post-review | Static | Background, notifications, paywall mockups (identical to FO-10) |
| 13 | Completion | Static | All loved affirmations (identical to FO-10) |

### Discovery Phase Detail (Steps 4-6)

#### Step 4: Goal — Static Chips (Same as FO-10)

**Question:** "What's your main goal with affirmations today, [name]?"

**Input:** Text field + predefined single-word topic chips (same 34-chip list as FO-10).

**Chip interaction:** Clicking a chip appends the topic to the text field. User can also type freely. Continue button requires input.

**Chips (static, not LLM-generated):**
Motivation, Focus, Inner peace, Energy boost, Better sleep, Body peace, Self-worth, Boundaries, Letting go, Healing, Gratitude, Positivity, Resilience, Anxiety relief, Stress relief, Courage, Hope, Joy, Patience, Mindfulness, Self-care, Forgiveness, Connection, Self-love, Breakup healing, Impulse control, Digital detox, Productivity, Morning boost, Night calm, Confidence, Calm, Self-discipline, Overthinking, Grief, Loneliness

**Rationale for static:** No user context to personalize against yet, and these chips perform well.

#### Step 5: Context — LLM-Adapted Question + Fragments (Skippable)

**Intent given to LLM:** "Understand what's going on in the user's life that makes this goal feel important right now. This adds emotional depth and specificity to the affirmations."

**LLM behavior:**
- **Adapt the question** to reference the user's goal answer. Example: if user said "Motivation", the question becomes _"Is something going on in your life right now that makes motivation feel extra important?"_ rather than the generic version.
- **Skip this step entirely** if the user's goal answer in step 4 was rich enough to already provide life context. Example: "I need motivation because I have a big exam tomorrow and I'm terrified" already answers the context question. When skipping, the discovery agent returns `{ skip: true }` and the UI silently advances to step 6.

**Input (when not skipped):** Text field + LLM-generated **hybrid fragments** ending with "..."

**Chip count:** 8 initial + 15 expanded (via "More" button).

**Example fragments** (for a user who said "Motivation"):
- "I've been putting things off because..."
- "It matters right now because I..."
- "I keep telling myself I should..."
- "What's making it hard is..."
- "I need this boost because..."

#### Step 6: Tone — LLM-Adapted Question + Single-Word Chips

**Intent given to LLM:** "Learn what tone of support the user wants for their affirmations."

**LLM behavior:**
- **Adapt the question** to reference the conversation so far. Example: if user discussed exam anxiety, the question might be _"If you had a supportive voice in your corner before that exam, how would you want it to sound?"_
- **Never skip** — tone is always asked.

**Input:** Text field + LLM-generated **single-word chips** describing tone qualities.

**Chip constraint:** Each chip must be a single word. No phrases, no sentences. Examples: "Gentle", "Motivational", "Empowering", "Caring", "Calm", "Bold", "Warm", "Clear", "Grounding", "Uplifting", "Compassionate", "Confident".

**Chip count:** 8 initial + 12 expanded (20 total, via "More" button).

**Chip interaction:** Clicking a word appends it to the text field (same pattern as step 4's topic chips). User can click multiple words and/or type freely.

**Helper text below chips:** "For example: calm, motivational, gentle, clear..."

### Heart Animation Transitions

Heart animations appear between discovery steps — same pattern as FO-10:
- Step 4 → Step 5 (or Step 6 if step 5 is skipped): "Thank you for sharing, [name]..."
- Step 5 → Step 6: "Thank you for sharing, [name]..."
- Step 6 → Generation: "You have been doing great, [name]! We are creating your personalized affirmations."

When step 5 is skipped, the heart animation after step 4 transitions directly to step 6. The user sees the "Thank you for sharing" animation, then step 6 loads — no indication that a step was skipped.

**During heart animations:** Chips for the next step are fetched in the background (same pattern as FO-10). If step 5 is being skipped, the skip decision comes from the discovery agent call that also triggers the next step's chip generation.

### Affirmation Engine (Steps 7-9)

**Identical to FO-10:**
- 5 affirmations per batch
- Card-by-card review: "Love it" / "Discard"
- Summary screen with "I'm good with these" / "I want to create more"
- Unlimited generation cycles with feedback loop
- The affirmation agent receives the full conversation context from steps 4-6 via the exchanges array
- Familiarity level is NOT passed to the affirmation agent (cosmetic only)

### Post-Review (Steps 10-13)

**Identical to FO-10:** Background selection, notifications, paywall mockups, completion screen.

## Technical Architecture

### What Changes from FO-10

| Component | FO-10 | FO-11 |
|-----------|-------|-------|
| Questions | Hardcoded in `FO10_QUESTIONS` array | Step 4 hardcoded; steps 5-6 LLM-generated |
| Discovery flow | Fixed 4 steps (4-7) | 2-3 steps (4-6), step 5 skippable |
| Discovery agent | Chip-only agent (no questions) | **Discovery agent** that returns question + chips + skip signal |
| Step 4 chips | Static single words | Static single words (unchanged) |
| Step 5 chips | LLM fragments ("...") | LLM fragments ("...") (unchanged format, but question is LLM-adapted) |
| Step 6 (was 7) | LLM full sentences about tone | LLM **single words** about tone |
| Step 7 (open-ended) | N/A (was support tone) | **Removed** |
| Familiarity | Passed to chip agent | Cosmetic only, not passed to discovery |
| Max discovery steps | Always 4 | 2 or 3 (step 5 skippable) |
| Total flow steps | 15 (0-14) | 14 (0-13) |

### Discovery Agent

Replaces FO-10's chip-only agent. A single agent that receives the step's intent and conversation history, and returns the adapted question + chips (or a skip signal).

**Model:** gpt-4o

**System prompt responsibilities:**
- Understand the intent of each discovery step
- Formulate questions that reference previous answers naturally
- Decide whether to skip step 5 based on richness of step 4 answer
- Generate chips matching the required format per step (fragments for step 5, single words for step 6)

**Input per call:**
```
## User Context
Name: [name]
Step: [5 or 6]

## Conversation So Far
Q: What's your main goal with affirmations today, [name]?
A: [user's answer]

[Q: [step 5 question if applicable]]
[A: [user's step 5 answer if applicable]]

## This Step's Intent
[Intent description for this step]

## Chip Format
[fragments ending with "..." | single words only]

## Your Task
Generate the question and chips for this step, or signal skip if appropriate.
```

**Output format:**

For a normal step:
```json
{
  "skip": false,
  "question": "Is something going on in your life right now that makes motivation feel extra important?",
  "initialChips": ["chip1", "chip2", "...8 total"],
  "expandedChips": ["chip9", "chip10", "...more"]
}
```

For a skipped step (step 5 only):
```json
{
  "skip": true,
  "question": "",
  "initialChips": [],
  "expandedChips": []
}
```

**Step-specific prompt templates (stored in KV store):**

- **Step 5 template:** Intent = understand life context. Chip format = fragments ending with "...". Include skip rule: "If the user's goal answer already provides rich context about what's happening in their life, set skip to true."
- **Step 6 template:** Intent = learn preferred support tone. Chip format = single words only. Never skip.

### Familiarity Handling

Step 3 (familiarity) remains in the UI for its nice UX moment (confetti, "Super, [name]!") but the selected value is **not passed** to the discovery agent or affirmation agent. This simplifies the agent prompts and removes a variable that wasn't meaningfully affecting output quality.

The `familiarityLevel` field remains in the state type for UI purposes but is not included in the `exchanges` array or agent prompts.

### Reuse from FO-10

Components reused directly (copied to `app/fo-11/components/`):
- `FragmentInput` — mode="sentences" renamed to mode="words" for step 6, mode="fragments" for step 5
- `HeartAnimation` — identical transition pattern
- `AffirmationCardFlow` — identical card review
- `AffirmationSummary` — identical summary with generate-more loop
- `StepWelcome` — steps 0-2 identical
- `StepFamiliarity` — step 3 identical (cosmetic change: value not passed further)
- `StepGoal` — step 4 identical (same static chips, same UI)
- `StepBackground`, `StepNotifications`, `StepPaywall` — post-review mockups
- `StepCompletion` — final screen

Infrastructure reused:
- Affirmation agent (create `fo-11-affirmation` based on `fo-10-affirmation`)
- KV store / template engine for prompt management
- Server action patterns
- Exchange-based data structure

### New/Modified Components

| Component | Change |
|-----------|--------|
| `fo-experience.tsx` | New state machine: 2-3 discovery steps instead of 4, skip logic for step 5 |
| `step-context.tsx` | **New** — replaces `step-why.tsx`. Uses `FragmentInput` with LLM-generated question and fragments |
| `step-tone.tsx` | **New** — replaces `step-support.tsx`. Uses `FragmentInput` mode="words" with LLM-generated question and single-word chips |
| `actions.ts` | New `generateDiscoveryStep()` server action that calls discovery agent |
| `types.ts` | New `FO11DiscoveryResponse` type with `skip` field; updated step constants |

### FragmentInput Mode Extension

The existing `FragmentInput` component supports `mode="sentences"` and `mode="fragments"`. FO-11 adds a third mode:

- **`mode="words"`**: Chips are single words. Clicking a chip appends the word to the text field (same as topic chip behavior in `StepGoal`).

**Styling differences for `mode="words"`:**
- Remove `max-w-[200px]` constraint (not needed for single words)
- Remove `whitespace-normal text-left` (single words don't wrap)
- Add `text-center` for centered word display
- Chips render as compact pills: `px-3 py-2 text-sm rounded-lg` (same base as other modes, but without the multi-line accommodations)
- The overall chip container uses `flex-wrap gap-2 justify-center` (same as other modes — single words naturally fit more per row)

### Data Flow

```
Step 4 (Goal):
  User answers → stored in exchanges[0]
  ↓
  Heart animation starts
  ↓ (concurrent)
  Call discovery agent for step 5 with exchanges[0]
  ↓
  Agent returns { skip: true } or { skip: false, question, chips }
  ↓
  If skip: call discovery agent for step 6 with exchanges[0]
  If no skip: show step 5 UI
  ↓
Step 5 (Context) — if not skipped:
  User answers → stored in exchanges[1]
  ↓
  Heart animation starts
  ↓ (concurrent)
  Call discovery agent for step 6 with exchanges[0..1]
  ↓
Step 6 (Tone):
  User answers → stored in exchanges[1 or 2]
  ↓
  Heart animation: "Creating your personalized affirmations..."
  ↓
  Generate affirmations using all exchanges
```

**Important:** When step 5 is skipped, the exchanges array has 2 entries (goal + tone). When step 5 is not skipped, it has 3 entries (goal + context + tone). The affirmation agent handles both cases — it reads the conversation content, not fixed indices.

### Exchange Structure

```typescript
// When step 5 is NOT skipped (3 exchanges):
exchanges: [
  { question: "What's your main goal...", answer: { text: "Motivation" } },
  { question: "Is something going on...", answer: { text: "I have an exam..." } },
  { question: "How would you want...", answer: { text: "Calm Gentle Caring" } },
]

// When step 5 IS skipped (2 exchanges):
exchanges: [
  { question: "What's your main goal...", answer: { text: "I need motivation because I have an exam tomorrow..." } },
  { question: "How would you want...", answer: { text: "Calm Gentle Caring" } },
]
```

## File Structure

```
app/fo-11/
  page.tsx                      # Page entry
  layout.tsx                    # Layout
  fo-11-layout-client.tsx       # Client layout
  actions.ts                    # Server actions: generateDiscoveryStep(), generateAffirmationBatchFO11()
  types.ts                      # FO11DiscoveryResponse, FO11OnboardingData, etc.
  info/
    page.tsx                    # Info page describing FO-11
  components/
    fo-experience.tsx           # Main state machine (modified for skip logic)
    step-welcome.tsx            # Steps 0-2 (from FO-10)
    step-familiarity.tsx        # Step 3 (from FO-10, cosmetic only)
    step-goal.tsx               # Step 4 (from FO-10)
    step-context.tsx            # Step 5 — NEW: LLM question + fragments, skippable
    step-tone.tsx               # Step 6 — NEW: LLM question + single-word chips
    fragment-input.tsx          # Extended with mode="words"
    heart-animation.tsx         # From FO-10
    affirmation-card-flow.tsx   # From FO-10
    affirmation-card.tsx        # From FO-10
    affirmation-summary.tsx     # From FO-10
    step-background.tsx         # From FO-10
    step-notifications.tsx      # From FO-10
    step-paywall.tsx            # From FO-10
    step-completion.tsx         # From FO-10

src/mastra/agents/fo-11/
  index.ts
  discovery-agent.ts            # NEW: generates adapted questions + chips + skip signal
  affirmation-agent.ts          # Based on FO-10 affirmation agent

src/db/seeds/
  fo-11.ts                      # KV store seeds for discovery + affirmation agents

e2e/
  fo-11.test.ts                 # E2E test
```

## Registration

### 1. Left Navigation Menu (`nav.config.ts`)

```typescript
{
  label: "FO-11",
  href: "/fo-11",
  children: [
    { label: "Demo", href: "/fo-11" },
    { label: "Info", href: "/fo-11/info" },
  ],
},
```

### 2. Overview Page (`app/overview/page.tsx`)

```typescript
{
  id: 'FO-11',
  name: 'Guided Discovery Hybrid',
  href: '/fo-11',
  tagline: 'Structured intent, conversational delivery',
  description: 'LLM adapts questions to prior answers and can skip redundant steps. Single-word tone chips. Best of FO-09 dynamics + FO-10 structure.',
  inputType: 'Static chips → LLM fragments → LLM single-word chips',
  outputType: 'Card curation (Love it / Discard)',
  highlight: 'Adaptive questions with skip logic',
},
```

### 3. Info Page (`app/fo-11/info/page.tsx`)

Create info page using `InfoPageWrapper` component.

## KV Store Keys

```
# Discovery Agent
versions.fo-11-discovery._info.default
versions.fo-11-discovery._model_name.default         # gpt-4o
versions.fo-11-discovery._temperature.default         # 0.8
versions.fo-11-discovery.system.default               # System prompt with intent framework
versions.fo-11-discovery.prompt_step_5.default        # Step 5: context intent + fragment format + skip rule
versions.fo-11-discovery.prompt_step_6.default        # Step 6: tone intent + single-word format + never skip

# Affirmation Agent
versions.fo-11-affirmation._info.default
versions.fo-11-affirmation._model_name.default        # gpt-4o
versions.fo-11-affirmation._temperature.default       # 0.9
versions.fo-11-affirmation.system.default             # Same as FO-10 affirmation system prompt
versions.fo-11-affirmation.prompt.default             # Initial generation prompt
versions.fo-11-affirmation.prompt_with_feedback.default  # With liked/discarded context
```

## Testing Strategy

### E2E Testing

Follow FO-10's E2E test structure and create `e2e/fo-11.test.ts`.

**Run command:** `node --import tsx e2e/fo-11.test.ts`

**Test coverage areas:**

| Area | What to Test |
|------|-------------|
| Welcome (steps 0-2) | Same as FO-10 — name input, navigation |
| Familiarity (step 3) | Button selection, confetti, auto-advance |
| Goal (step 4) | Static single-word chips render, chip click appends to text field, free text works, continue button |
| Context (step 5) — when shown | LLM question appears (not hardcoded), fragment chips load ("..." endings), fragment click behavior |
| Context (step 5) — when skipped | Step is silently skipped, UI goes from step 4 heart animation directly to step 6 |
| Tone (step 6) | LLM question appears, single-word chips (not sentences), chip click appends word, multiple words selectable |
| Heart animations | Animation appears between steps, correct messages |
| Skip flow | When goal answer is rich, step 5 is skipped and step 6 loads directly |
| Non-skip flow | When goal answer is brief (e.g., single word "Motivation"), step 5 appears |
| Affirmation generation (step 7) | Loading state, 5 affirmations generated |
| Card review (step 8) | "Love it" / "Discard" per card, progress counter |
| Summary (step 9) | Loved affirmations displayed, "I'm good" and "create more" buttons |
| Generate more loop | "Create more" triggers new batch, feedback context passed correctly |
| Post-review (steps 10-13) | Mockup screens, completion shows all loved affirmations |

**Key test scenarios for skip logic:**

1. **Brief goal → no skip:** User types "Motivation" → step 5 appears with adapted question → step 6 appears
2. **Rich goal → skip:** User types "I need motivation because I have a big exam tomorrow and I'm scared" → step 5 is skipped → step 6 appears directly
3. **Both paths produce affirmations:** Verify affirmation generation works with both 2-exchange and 3-exchange flows

**Reusable helpers from FO-10 E2E:**
- `waitForText()`, `waitForTextContaining()`
- `waitForThinkingToFinish()`, `waitForHeartAnimation()`
- `clickButton()`, `clickSentence()`, `clickFragment()`
- `countChips()`
- `getTextareaValue()`

### Manual Verification

- **Question adaptation:** Does the LLM reference the user's goal in steps 5-6 questions? (e.g., "motivation" appears in the question)
- **Skip intelligence:** Does the agent correctly identify when step 4 already answers step 5? Does it avoid skipping when the goal answer is brief?
- **Tone chip quality:** Are tone chips truly single words, not phrases? Are they relevant to the conversation?
- **Fragment quality:** Are step 5 fragments relevant to the user's stated goal?
- **Affirmation quality with 2 vs 3 exchanges:** Are affirmations equally good when step 5 is skipped?

### Edge Cases

- User types only (ignores all chips) — flow should still work
- User clicks chips without typing — flow should still work
- LLM returns phrases instead of single words for tone — display as-is, log warning
- LLM returns `skip: true` for step 6 (should never happen) — ignore skip, show step 6 anyway
- Discovery agent fails — show error with retry button
- Empty text submission — blocked (require at least chip selection or typed text)
- LLM returns fewer than 8 chips — UI handles gracefully (show what we get)

## Open Questions

All questions resolved during design session:

- ~~Familiarity handling~~ → Cosmetic only, not passed to agents
- ~~Open-ended "anything else" step~~ → Removed entirely
- ~~Goal chips~~ → Static (same as FO-10)
- ~~Tone chips~~ → LLM-generated single words
- ~~Context chip format~~ → Fragments ("...")
- ~~Skip UX~~ → Silent skip (no visible indication to user)

## References

- FO-10 spec: `docs/projects/2026-02-09-fo-10/2026-02-09-fo-10-spec.md`
- FO-10 UI: `app/fo-10/components/fo-experience.tsx`
- FO-10 chip agent: `src/mastra/agents/fo-10/chip-agent.ts`
- FO-10 affirmation agent: `src/mastra/agents/fo-10/affirmation-agent.ts`
- FO-10 seed data: `src/db/seeds/fo-10.ts`
- FO-09 spec: `docs/projects/2026-01-30-fo-09/2026-01-30-fo-09-spec.md`
- FO-09 discovery agent (dynamic questions): `app/fo-09/actions.ts`
- E2E testing setup: `docs/current/e2e-testing.md`
- E2E config: `docs/current/e2e/e2e-config.md`
